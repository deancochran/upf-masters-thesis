{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dgl.data import DGLDataset, download, extract_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/LFM-1b/LFM-1b_UGP.zip from http://www.cp.jku.at/datasets/LFM-1b/LFM-1b_UGP.zip...\n"
     ]
    }
   ],
   "source": [
    "zip_file_path = os.path.join('../data/LFM-1b', 'LFM-1b_UGP.zip')\n",
    "extract_archive(download('http://www.cp.jku.at/datasets/LFM-1b/LFM-1b_UGP.zip', path=zip_file_path, overwrite=False), '../data/LFM-1b/LFM-1b_UGP', overwrite=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_archive('../data/LFM-1b/LFM-1b_UGP.zip', '../data/LFM-1b', overwrite=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "negvalues=np.unique([1,2,3,3, 7,3,4,4,5,5,5, 8])\n",
    "values=np.unique([1,2,3,3,3,4,4,5,5,5])\n",
    "series=pd.Series(values)\n",
    "\n",
    "series.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 00:53:07.624971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-12 00:53:07.624995: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from utils import load_txt_df, mapIds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path='../data/LFM-1b/preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df in ../data/LFM-1b/preprocessed/LFM-1b_artists.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 17.25it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df in ../data/LFM-1b/preprocessed/LFM-1b_albums.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [00:08<00:00, 16.38it/s]\n"
     ]
    }
   ],
   "source": [
    "file_path=preprocessed_path+'/LFM-1b_artists.txt'\n",
    "artist_df = load_txt_df(file_path, type='artist')\n",
    "\n",
    "file_path=preprocessed_path+'/LFM-1b_albums.txt'\n",
    "album_df = load_txt_df(file_path, type='album')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "No kernel associated with the notebook. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "bad_ids=[]\n",
    "total=len(album_df['artist_id'].unique())\n",
    "count=0\n",
    "for id in album_df['artist_id'].unique():\n",
    "    if id not in artist_df['artist_id'].unique():\n",
    "        bad_ids.append(id)\n",
    "        count+=1\n",
    "        print('\\r', f'{(count/total):.2f} complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df in ../data/LFM-1b/preprocessed/LFM-1b_artists.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:01, 16.77it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(artist_mapping.keys()) 2361790\n",
      "593964 in df[\"artist_id\"].values False\n",
      "593964 in artist_mapping.keys() False\n"
     ]
    }
   ],
   "source": [
    "df = load_txt_df(file_path, type='artist')\n",
    "# -------------------------ARTIST ID MAPPING-------------------------\n",
    "mappings['artist_mapping'] = {id: i for i, id in enumerate(df['artist_id'].values)}\n",
    "# -------------------------ARTIST DF RE-ID-------------------------\n",
    "print('len(artist_mapping.keys())',len(mappings['artist_mapping'].keys()))\n",
    "print('593964 in df[\"artist_id\"].values',593964 in df['artist_id'].values)\n",
    "print('593964 in artist_mapping.keys()',593964 in mappings['artist_mapping'])\n",
    "df = mapIds(df, cols=['artist_id'], mappings=[mappings['artist_mapping']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_unique_le_ids = load_txt_df(preprocessed_path+'/LFM-1b_LEs.txt', type='le', return_unique_ids=True, id_list=['artist_id', 'album_id', 'track_id', 'user_id'])\n",
    "preprocessed_unique_user_ids = load_txt_df(preprocessed_path+'/LFM-1b_users.txt', type='user', return_unique_ids=True, id_list=['user_id'])\n",
    "preprocessed_unique_album_ids = load_txt_df(preprocessed_path+'/LFM-1b_albums.txt', type='album', return_unique_ids=True, id_list=['album_id'])\n",
    "preprocessed_unique_track_ids = load_txt_df(preprocessed_path+'/LFM-1b_tracks.txt', type='track', return_unique_ids=True, id_list=['track_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
