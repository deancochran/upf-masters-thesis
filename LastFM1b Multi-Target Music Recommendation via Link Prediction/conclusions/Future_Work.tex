
\section{Future Work}
As for the decisions to be made from here on. I believe that this project has the capability of providing the promised results, given the opportunity to utilize a device with powerful enough hardware to compute the necessary node embed dings for large graphs. Each as it has not been tested on larger subsets, I am not for certain of the required storage space to process the graph, however I do know that it is not larger than the maximum storage of the graph object which by design of the data set is less than 8GB.

However, given the likely occurrence of utilizing larger, more powerful devices as unlikely, validating the user to model of the small subset of the LastFM1b is a primary step in justifying why this data set should be used. In doing so the evaluation metrics for recommending artists to users will also be completed.

Aside from training, the data loading repository and preliminary masters thesis code has already been published on GitHub. 


https://github.com/deancochran/upf-masters-thesis

https://github.com/deancochran/DGL\textunderscore{}LFM1b



Therefore providing significant versioning of the repositories used in this thesis will justify the commitment to reproducible code many published graph neural papers do not submit.


Lastly, as mentioned in the discussion the LastFM2b data set has been developed. Though, the data loader for LastFM1b has been tested, it has not been ran completely for a full graph evaluation. It begs the question of whether it could be a better use of my knowledge of custom data loaders for the deep graph library framework, to build the data loader for the LastFM2b data set as well