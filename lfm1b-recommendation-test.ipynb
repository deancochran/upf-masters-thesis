{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-08 23:24:28.952342: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-08 23:24:28.952390: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import copy\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from DGL_LFM1b.data_utils import *\n",
    "from utils.utils import convert_to_gpu\n",
    "from dgl.data.utils import load_graphs\n",
    "from utils.LinkScorePredictor import LinkScorePredictor\n",
    "from model.R_HGNN import R_HGNN\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: right;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Arugments and initializing graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation with Link Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DGL_LFM1b.data_utils import get_fileSize, get_col_names, setType, isValid, get_preprocessed_ids\n",
    "\n",
    "def get_ids_from_txtFile(path_txt_file, type ,ids):\n",
    "    chunksize=1000000\n",
    "    chunks=[]\n",
    "    size = get_fileSize(path_txt_file)\n",
    "    col_names=get_col_names(type)\n",
    "    df_chunks = pd.read_csv(path_txt_file, names=col_names, sep=\"\\t\", encoding='utf8', header = 0, chunksize=chunksize)\n",
    "    for chunk in tqdm(df_chunks, total=size//chunksize):\n",
    "        for col in chunk.columns:\n",
    "            try:\n",
    "                chunk[col]=chunk[col].apply(lambda x: setType(x, col))\n",
    "            except:\n",
    "                chunk[col]=chunk[col].apply(lambda x: isValid(x, col))\n",
    "                chunk[col]=chunk[col].apply(lambda x: setType(x, col))\n",
    "        chunk = chunk[chunk[col_names[0]].isin(ids)] \n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks)\n",
    "    # print(f'{type} df has shpe:',df.shape)\n",
    "    return df\n",
    "\n",
    "def topK_playcounts(path_to_txt_data, series, type, k, user_id):\n",
    "    val_count_pairs=series.value_counts().head(k)\n",
    "    ids=list(val_count_pairs.keys())\n",
    "    type_df = get_ids_from_txtFile(path_to_txt_data, type, ids)\n",
    "    print(f'Top {k} {type}s for user {user_id}')\n",
    "    print('ID       PLAYCOUNT      NAME')\n",
    "    for id, playcount in val_count_pairs.items():\n",
    "        row=type_df.loc[type_df[type+'_id'] == id]\n",
    "        name = row[type+'_name'].item()\n",
    "        print(f'{id}        {playcount}         {name} ')\n",
    "\n",
    "def topK_recommendations(path_to_txt_data, ids, type, k, user_id, artist_path_to_txt_data=None):\n",
    "    type_df = get_ids_from_txtFile(path_to_txt_data, type, ids)\n",
    "    if artist_path_to_txt_data != None:\n",
    "        artist_ids=[type_df.loc[type_df[type+'_id'] == id]['artist_id'].item() for id in ids]\n",
    "        artist_df= get_ids_from_txtFile(artist_path_to_txt_data, type='artist', ids=artist_ids)\n",
    "        artist_name_mapping={id: artist_df.loc[artist_df['artist_id'] == id]['artist_name'].item() for id in artist_ids}\n",
    "\n",
    "    print(f'Top {k} {type} recommendations for user #{user_id}')\n",
    "    if artist_path_to_txt_data != None:\n",
    "        print('ID           ARTIST_NAME             NAME')\n",
    "    else:\n",
    "        print('ID             NAME')\n",
    "    for id in ids:\n",
    "        row=type_df.loc[type_df[type+'_id'] == id]\n",
    "        name = row[type+'_name'].item()\n",
    "        try:\n",
    "            artist_id = row['artist_id'].item()\n",
    "            print(f'{id}        {artist_name_mapping[artist_id]}        {name}')\n",
    "        except:\n",
    "            print(f'{id}  {name}')\n",
    "\n",
    "def displayTopKRecommendations(graph, model, type, sampled_edge_type, k, user_id, typeFile_path, userFile_path, artists_path, albums_path, tracks_path, les_path, device, artist_path_to_txt_data=None):\n",
    "    input_features = {(stype, etype, dtype): graph.srcnodes[dtype].data['feat'] for stype, etype, dtype in graph.canonical_etypes}\n",
    "    nodes_representation, _ = model[0].inference(graph, copy.deepcopy(input_features), device=device)\n",
    "    user_nodes_representation=nodes_representation['user']\n",
    "    type_nodes_representation=nodes_representation[type]\n",
    "    # C = torch.mm(A, B.T)  # same as C = A @ B.T\n",
    "    listen_to_type_likelihood = C = th.mm(user_nodes_representation, type_nodes_representation.T)\n",
    "\n",
    "    print(f'listen_to_{type}_likelihood',listen_to_type_likelihood.shape)\n",
    "    user_type_recommendations={}\n",
    "    for u_id, row in enumerate(tqdm(listen_to_type_likelihood, total=int(listen_to_type_likelihood.shape[0]))):\n",
    "        for id, _ in enumerate(row):\n",
    "            try:\n",
    "                graph.edge_id(u_id,id, etype=sampled_edge_type)\n",
    "            except:\n",
    "                if u_id in user_type_recommendations.keys():\n",
    "                    user_type_recommendations[u_id].append((u_id, id, listen_to_type_likelihood[u_id,id].item()))\n",
    "                else:\n",
    "                    user_type_recommendations[u_id]=list()\n",
    "                    user_type_recommendations[u_id].append((u_id, id, listen_to_type_likelihood[u_id,id].item()))\n",
    "\n",
    "    rev_user_mapping = get_id_mapping(path_to_file=userFile_path, type='user', reverse=True)\n",
    "    rev_type_mapping = get_id_mapping(path_to_file=typeFile_path, type=type, reverse=True)\n",
    "    user_listens=get_ids_from_txtFile(path_txt_file=les_path, type='le' , ids=[rev_user_mapping[user_id]])\n",
    "    topK_playcounts(path_to_txt_data=artists_path, series=user_listens['artist_id'], type='artist', k=k, user_id=user_id)\n",
    "    topK_playcounts(path_to_txt_data=albums_path, series=user_listens['album_id'], type='album', k=k, user_id=user_id)\n",
    "    topK_playcounts(path_to_txt_data=tracks_path, series=user_listens['track_id'], type='track', k=k, user_id=user_id)\n",
    "    user_type_recommendations={key: sorted(value, key=lambda x: x[2], reverse=True)[:k] for key, value in  user_type_recommendations.items()}\n",
    "    user_type_recommendations=[rev_type_mapping[id] for _, id, _ in user_type_recommendations[user_id]]\n",
    "    if artist_path_to_txt_data !=None:\n",
    "        topK_recommendations(path_to_txt_data=typeFile_path, ids=user_type_recommendations, type=type, k=k, user_id=user_id, artist_path_to_txt_data=artists_path)\n",
    "    else:\n",
    "        topK_recommendations(path_to_txt_data=typeFile_path, ids=user_type_recommendations, type=type, k=k, user_id=user_id)\n",
    "\n",
    "def get_result_folder_path(root, date, sample_edge_type):\n",
    "    return f'{root}/lfm1b/{date}/{sample_edge_type}'\n",
    "\n",
    "def get_result_folder_args(root, date, sample_edge_type):\n",
    "    return get_result_folder_path(root, date, sample_edge_type)+'/args.json'\n",
    "\n",
    "def get_result_folder_model_state(root, date, sample_edge_type):\n",
    "    return get_result_folder_path(root, date, sample_edge_type)+f'/{sample_edge_type}.pkl'\n",
    "\n",
    "def get_result_folder_metrics(root, date, sample_edge_type):\n",
    "    return get_result_folder_path(root, date, sample_edge_type)+f'/metrics.pkl'\n",
    "\n",
    "\n",
    "def get_id_mapping(path_to_file, type, reverse=False):\n",
    "    ids=get_preprocessed_ids(path_to_file, return_unique_ids=False, type=type, id_list=get_col_names(type))[f'{type}_id']\n",
    "    if reverse:\n",
    "        return {i: row for i, row in enumerate(ids)}\n",
    "    else:\n",
    "        return {row: i for i, row in enumerate(ids)}\n",
    "\n",
    "\n",
    "def build_model(data_post_path,  date, args, sample_edge_type, root='results/'):\n",
    "    model_state_path=get_result_folder_model_state(root, date, sample_edge_type)\n",
    "    glist,_=load_graphs(f'{data_post_path}/lastfm1b.bin')\n",
    "    hg=glist[0]\n",
    "    r_hgnn = R_HGNN(graph=hg,\n",
    "                input_dim_dict={ntype: hg.nodes[ntype].data['feat'].shape[1] for ntype in hg.ntypes},\n",
    "                hidden_dim=args['hidden_dim'], \n",
    "                relation_input_dim=args['rel_input_dim'],\n",
    "                relation_hidden_dim=args['rel_hidden_dim'],\n",
    "                num_layers=args['num_layers'], \n",
    "                n_heads=args['num_heads'], \n",
    "                dropout=args['dropout'],\n",
    "                residual=args['residual'], \n",
    "                norm=args['norm'])\n",
    "    link_scorer = LinkScorePredictor(args['hidden_dim'] * args['num_heads'])\n",
    "\n",
    "    model = nn.Sequential(r_hgnn, link_scorer)\n",
    "    model = convert_to_gpu(model, device=args['device'])\n",
    "    model.load_state_dict(th.load(model_state_path, map_location=args['device']))\n",
    "    return model\n",
    "\n",
    "def get_file_pre_path(data_pre_path, type):\n",
    "    print('type:',type)\n",
    "    if type=='user':\n",
    "        return data_pre_path+'LFM-1b_users.txt'\n",
    "    elif type=='album':\n",
    "        return data_pre_path+'LFM-1b_albums.txt'\n",
    "    elif type=='artist':\n",
    "        return data_pre_path+'LFM-1b_artists.txt'\n",
    "    elif type=='track':\n",
    "        return data_pre_path+'LFM-1b_tracks.txt'\n",
    "    elif type=='le':\n",
    "        return data_pre_path+'LFM-1b_LEs.txt'\n",
    "    elif type=='genre':\n",
    "        return data_pre_path+'genres_allmusic.txt'\n",
    "    else:\n",
    "        raise Exception('bad \"type\" parameter in get_col_names')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing LFM1b\n",
      "\t Loading Mapping Data from users.txt\n",
      "---------------------------- Loading Preprocessed user file  ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 110.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Loading Mapping Data from allmusic.txt\n",
      "---------------------------- Loading Preprocessed genre file  ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 163.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Loading Mapping Data from artists.txt\n",
      "---------------------------- Loading Preprocessed artist file  ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 63.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remapping_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8964/8964 [00:00<00:00, 825616.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Loading Graph Data from allmusic.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8964/8964 [00:00<00:00, 3513479.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remapping_ids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30118/30118 [00:00<00:00, 1215612.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading artist listen events for every user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of user artist edges: 108476\n",
      "\t Creating DGL HeteroGraph from Graph Data\n",
      "Graph(num_nodes={'artist': 8964, 'genre': 21, 'user': 10},\n",
      "      num_edges={('artist', 'artist_listened_by', 'user'): 108476, ('artist', 'in_genre', 'genre'): 30118, ('genre', 'is_genre_of', 'artist'): 30118, ('user', 'listened_to_artist', 'artist'): 108476},\n",
      "      metagraph=[('artist', 'user', 'artist_listened_by'), ('artist', 'genre', 'in_genre'), ('user', 'artist', 'listened_to_artist'), ('genre', 'artist', 'is_genre_of')])\n",
      "\t Creating metapath2vec node embeddings\n",
      "using metapath [('user', 'listened_to_artist', 'artist'), ('artist', 'in_genre', 'genre'), ('genre', 'is_genre_of', 'artist'), ('artist', 'artist_listened_by', 'user')]\n",
      "training...\n",
      " Epoch: 05 of 6, Step: 001/1, Loss: 2.7770 loading...\n",
      "saved! embedding_dict\n",
      "\t Loading features from artists.txt\n",
      "\t Loading features from allmusic.txt\n",
      "\t Loading features from users.txt\n",
      "loading artist listen events for every user\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graph...\n",
      "loading graph memory size....\n",
      "graph is 19897 bytes large\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "from DGL_LFM1b.DGL_LFM1b import LFM1b\n",
    "dataset=LFM1b(tracks=False,albums=False, overwrite_processed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preform_recommendations(graph, data_pre_path, data_post_path,  date, sample_edge_type, root, u_id, k):\n",
    "    args_path=get_result_folder_args(root, date, sample_edge_type)\n",
    "    args = json.load(open(args_path))\n",
    "    print('args',args)\n",
    "    model=build_model(data_post_path,  date, args, sample_edge_type, root='./results/')\n",
    "\n",
    "    displayTopKRecommendations(\n",
    "    graph=graph,\n",
    "    model=model,\n",
    "    type='artist',\n",
    "    sampled_edge_type=sample_edge_type,\n",
    "    k=k,\n",
    "    user_id=u_id,\n",
    "    typeFile_path=get_file_pre_path(data_pre_path,type='artist'),\n",
    "    userFile_path=data_pre_path+'LFM-1b_users.txt',\n",
    "    artists_path=data_pre_path+'LFM-1b_artists.txt',\n",
    "    albums_path=data_pre_path+'LFM-1b_albums.txt',\n",
    "    tracks_path=data_pre_path+'LFM-1b_tracks.txt',\n",
    "    les_path=data_pre_path+'LFM-1b_LEs.txt',\n",
    "    device=args['device']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args {'seed': 0, 'sample_edge_rate': 0.1, 'num_layers': 2, 'batch_size': 512, 'num_neg_samples': 5, 'node_min_neighbors': 10, 'shuffle': True, 'drop_last': False, 'num_workers': 4, 'hidden_dim': 32, 'rel_input_dim': 12, 'rel_hidden_dim': 32, 'num_heads': 8, 'dropout': 0.5, 'residual': True, 'norm': True, 'opt': 'adam', 'weight_decay': 0.0, 'epochs': 100, 'patience': 25, 'split_by_users': True, 'device': 'cuda', 'artists': True, 'albums': False, 'tracks': False, 'playcount_weight': False, 'norm_playcount_weight': False, 'metapath2vec': True, 'emb_dim': 32, 'walk_length': 64, 'context_size': 7, 'walks_per_node': 3, 'metapath2vec_epochs_batch_size': 128, 'learning_rate': 0.001, 'metapath2vec_epochs': 5, 'logs': 100, 'n_users': 10, 'popular_artists': True, 'model_parameters': 1775158}\n",
      "type: artist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                             | 0/8 [00:00<?, ?it/s]/home/dean/dev/upf-masters-thesis/.env/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "inference for the 7-th batch in model 0-th layer: 100%|███████████████████████████████████| 8/8 [00:00<00:00, 16.58it/s]\n",
      "inference for the 7-th batch in model 1-th layer: 100%|███████████████████████████████████| 8/8 [00:00<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listen_to_artist_likelihood torch.Size([10, 8964])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/dean/dev/upf-masters-thesis/.env/lib/python3.8/site-packages/dgl/heterograph.py:2978: DGLWarning: DGLGraph.edge_id is deprecated. Please use DGLGraph.edge_ids.\n",
      "  dgl_warning(\"DGLGraph.edge_id is deprecated. Please use DGLGraph.edge_ids.\")\n",
      "100%|██████████| 10/10 [00:34<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Loading Preprocessed user file  ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 153.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------- Loading Preprocessed artist file  ----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 93.62it/s]\n",
      "1it [00:00,  3.24it/s]\n",
      "1it [00:00, 66.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artists for user 0\n",
      "ID       PLAYCOUNT      NAME\n",
      "10624        176         Discharge \n",
      "811        142         Miles Davis \n",
      "259        101         R.E.M. \n",
      "24082        100         Scritti Politti \n",
      "7165        82         Elis Regina \n",
      "722        72         The Beach Boys \n",
      "6100        69         A Tribe Called Quest \n",
      "329        69         The Clash \n",
      "2646        69         Earth, Wind & Fire \n",
      "23154        62         Meat Puppets \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.48s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 albums for user 0\n",
      "ID       PLAYCOUNT      NAME\n",
      "21632        118         Hear Nothing See Nothing Say Nothing \n",
      "8457        43         Greatest Hits \n",
      "5276240        41         Belly Of The Sun \n",
      "34551        39         Los Angeles \n",
      "787657        36         Moondog (The Viking Of Sixth Avenue) \n",
      "676735        35         Provision \n",
      "12424198        34         Never Again - Discharge \n",
      "12424361        33         Sweet Child - Pentangle \n",
      "3675        30         Greatest Hits \n",
      "11717875        29         Midnight Blue \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:15,  1.67s/it]                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 tracks for user 0\n",
      "ID       PLAYCOUNT      NAME\n",
      "623707        19         Waters Of March \n",
      "299489        17         In The Eye \n",
      "900800        15         We Are Family \n",
      "25198490        14         流れるは飛ぶに非ず \n",
      "1739282        14         All That We Are \n",
      "190224        14         Nine Out Of Ten \n",
      "959150        12         Piss Factory \n",
      "2677719        12         蒼氓 \n",
      "60125        11         Hear Nothing See Nothing Say Nothing \n",
      "3709266        11         Tem Boi Na Linha \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 60.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artist recommendations for user #0\n",
      "ID             NAME\n",
      "258  Mr. Big\n",
      "6199  The Dillinger Escape Plan\n",
      "40419  Brazilian Girls\n",
      "4173  Young the Giant\n",
      "36499  The Acacia Strain\n",
      "9518  Jay-Z & Kanye West\n",
      "26866  Kryptic Minds\n",
      "543  Band of Horses\n",
      "3054  Alina Devecerski\n",
      "26144  MellowHype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uer_id=0\n",
    "k=10\n",
    "graph=dataset[0]\n",
    "data_root_path='results'\n",
    "data_pre_path='data/DGL_LFM1b/preprocessed/'\n",
    "data_post_path='data/DGL_LFM1b/processed/'\n",
    "date='06_07_2022_21:24:53'\n",
    "sample_edge_type='listened_to_artist'\n",
    "\n",
    "preform_recommendations(graph, data_pre_path, data_post_path,  date, sample_edge_type, data_root_path, uer_id, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
